{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b166050",
   "metadata": {},
   "source": [
    "# Fu-Predictor\n",
    "### Data Analysis\n",
    "\n",
    "---\n",
    "\n",
    "by Fujyn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e4a3c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Usage\n",
    "\n",
    "the goal it to know the accuracy of the dataset and analyze the efficiency for fitting it into a ML model :\n",
    "- Clean Null value\n",
    "- Apply Logistic Regresion\n",
    "- Mesure the accuracy score\n",
    "- Check the correlation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02801bd1",
   "metadata": {},
   "source": [
    "## Package Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bdb219c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import default library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import usefull library\n",
    "from sklearn import svm # for Discriminator\n",
    "from sklearn.model_selection import train_test_split # for train-test split \n",
    "from sklearn.preprocessing import StandardScaler # for feature scaling\n",
    "from sklearn.model_selection import GridSearchCV # for fine-tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics # for evaluation\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression # For data analizis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.impute import SimpleImputer # To replace null value in dataframe\n",
    "\n",
    "import matplotlib.pyplot as plt  # for visualization \n",
    "import seaborn as sns  # for coloring "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fdbcb1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load Working Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce104d16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>G_home</th>\n",
       "      <th>W_PCT_home</th>\n",
       "      <th>G_prev_home</th>\n",
       "      <th>W_PCT_prev_home</th>\n",
       "      <th>G_away</th>\n",
       "      <th>W_PCT_away</th>\n",
       "      <th>G_prev_away</th>\n",
       "      <th>W_PCT_prev_away</th>\n",
       "      <th>WIN_PRCT_home_2g</th>\n",
       "      <th>...</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>GAME_DATE_EST_x</th>\n",
       "      <th>SEASON_x</th>\n",
       "      <th>HOME_TEAM_WINS_x</th>\n",
       "      <th>GAME_DATE_EST_y</th>\n",
       "      <th>SEASON_y</th>\n",
       "      <th>HOME_TEAM_WINS_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20700001</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.707</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.390</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.256</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.462</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2007-10-30</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-10-30</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20700002</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.549</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.634</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.273</td>\n",
       "      <td>23.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2007-10-30</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-10-30</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20700003</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.622</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.455</td>\n",
       "      <td>24.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2007-10-30</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-10-30</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20700008</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.817</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.500</td>\n",
       "      <td>23.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2007-10-31</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>2007-10-31</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20700011</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.549</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.378</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.412</td>\n",
       "      <td>27.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2007-10-31</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-10-31</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>20700096</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.402</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.317</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.537</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.143</td>\n",
       "      <td>17.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>20700097</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.378</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.200</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>20700099</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.268</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.598</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.634</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.211</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>20700101</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.707</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.768</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.549</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.125</td>\n",
       "      <td>15.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20700102</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.744</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.659</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.402</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.280</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.375</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>2007-11-13</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     GAME_ID  G_home  W_PCT_home  G_prev_home  W_PCT_prev_home  G_away  \\\n",
       "0   20700001    82.0       0.707         82.0            0.768    82.0   \n",
       "1   20700002    82.0       0.512         82.0            0.549    82.0   \n",
       "2   20700003    82.0       0.512         82.0            0.415    82.0   \n",
       "3   20700008    82.0       0.610         82.0            0.610    82.0   \n",
       "4   20700011    82.0       0.549         82.0            0.537    82.0   \n",
       "..       ...     ...         ...          ...              ...     ...   \n",
       "95  20700096    82.0       0.402         82.0            0.317    82.0   \n",
       "96  20700097    82.0       0.488         82.0            0.439    82.0   \n",
       "97  20700099    82.0       0.268         82.0            0.598    82.0   \n",
       "98  20700101    82.0       0.707         82.0            0.768    82.0   \n",
       "99  20700102    82.0       0.744         82.0            0.659    82.0   \n",
       "\n",
       "    W_PCT_away  G_prev_away  W_PCT_prev_away  WIN_PRCT_home_2g  ...  \\\n",
       "0        0.390         82.0            0.256               0.5  ...   \n",
       "1        0.634         82.0            0.415               0.0  ...   \n",
       "2        0.622         82.0            0.500               0.5  ...   \n",
       "3        0.817         82.0            0.732               0.0  ...   \n",
       "4        0.378         82.0            0.427               0.5  ...   \n",
       "..         ...          ...              ...               ...  ...   \n",
       "95       0.537         82.0            0.634               0.5  ...   \n",
       "96       0.378         82.0            0.427               0.5  ...   \n",
       "97       0.634         82.0            0.415               0.0  ...   \n",
       "98       0.512         82.0            0.549               1.0  ...   \n",
       "99       0.402         82.0            0.280               1.0  ...   \n",
       "\n",
       "    FT_PCT_away  FG3_PCT_away  AST_away  REB_away  GAME_DATE_EST_x  SEASON_x  \\\n",
       "0         0.765         0.462      15.0      40.0       2007-10-30      2007   \n",
       "1         0.677         0.273      23.0      49.0       2007-10-30      2007   \n",
       "2         0.833         0.455      24.0      56.0       2007-10-30      2007   \n",
       "3         0.850         0.500      23.0      36.0       2007-10-31      2007   \n",
       "4         0.593         0.412      27.0      52.0       2007-10-31      2007   \n",
       "..          ...           ...       ...       ...              ...       ...   \n",
       "95        0.682         0.143      17.0      38.0       2007-11-13      2007   \n",
       "96        0.571         0.200      16.0      44.0       2007-11-13      2007   \n",
       "97        0.708         0.211      17.0      36.0       2007-11-13      2007   \n",
       "98        0.857         0.125      15.0      50.0       2007-11-13      2007   \n",
       "99        0.727         0.375      19.0      36.0       2007-11-13      2007   \n",
       "\n",
       "    HOME_TEAM_WINS_x  GAME_DATE_EST_y  SEASON_y  HOME_TEAM_WINS_y  \n",
       "0                  1       2007-10-30      2007                 1  \n",
       "1                  0       2007-10-30      2007                 0  \n",
       "2                  0       2007-10-30      2007                 0  \n",
       "3                  0       2007-10-31      2007                 0  \n",
       "4                  1       2007-10-31      2007                 1  \n",
       "..               ...              ...       ...               ...  \n",
       "95                 1       2007-11-13      2007                 1  \n",
       "96                 1       2007-11-13      2007                 1  \n",
       "97                 1       2007-11-13      2007                 1  \n",
       "98                 1       2007-11-13      2007                 1  \n",
       "99                 1       2007-11-13      2007                 1  \n",
       "\n",
       "[100 rows x 111 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read game formated csv file\n",
    "df = pd.read_csv('../data/games_formated.csv')\n",
    "\n",
    "df = df.sort_values(by='GAME_DATE_EST_x').reset_index(drop=True)\n",
    "\n",
    "# Sort dataframe by GAME_DATE_EST\n",
    "df = df.loc[df[\"GAME_DATE_EST_x\"] >= \"2007-10-28\"].reset_index(drop=True)\n",
    "\n",
    "# Display first 10 lines of dataset\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13d75f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20539 entries, 0 to 20538\n",
      "Columns: 111 entries, GAME_ID to HOME_TEAM_WINS_y\n",
      "dtypes: float64(102), int64(7), object(2)\n",
      "memory usage: 17.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121862ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Check if the dataframe contains null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8bff9790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3550bb32",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Select features to use in the classifier prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9eac67c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G_home</th>\n",
       "      <th>G_away</th>\n",
       "      <th>W_PCT_home</th>\n",
       "      <th>W_PCT_prev_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>FG3_PCT_home</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>W_PCT_away</th>\n",
       "      <th>...</th>\n",
       "      <th>FT_PCT_home_15g</th>\n",
       "      <th>FG3_PCT_home_15g</th>\n",
       "      <th>AST_home_15g</th>\n",
       "      <th>REB_home_15g</th>\n",
       "      <th>WIN_PRCT_away_15g</th>\n",
       "      <th>FG_PCT_away_15g</th>\n",
       "      <th>FT_PCT_away_15g</th>\n",
       "      <th>FG3_PCT_away_15g</th>\n",
       "      <th>AST_away_15g</th>\n",
       "      <th>REB_away_15g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.250</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716933</td>\n",
       "      <td>0.400533</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>41.266667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.443267</td>\n",
       "      <td>0.779800</td>\n",
       "      <td>0.372867</td>\n",
       "      <td>18.133333</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.250</td>\n",
       "      <td>18.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.707267</td>\n",
       "      <td>0.356267</td>\n",
       "      <td>20.466667</td>\n",
       "      <td>43.800000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.447200</td>\n",
       "      <td>0.774400</td>\n",
       "      <td>0.368600</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>41.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.261</td>\n",
       "      <td>19.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749400</td>\n",
       "      <td>0.343067</td>\n",
       "      <td>19.133333</td>\n",
       "      <td>39.600000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.448267</td>\n",
       "      <td>0.721467</td>\n",
       "      <td>0.338667</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>43.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.250</td>\n",
       "      <td>13.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727933</td>\n",
       "      <td>0.309867</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>42.600000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.449867</td>\n",
       "      <td>0.800667</td>\n",
       "      <td>0.346667</td>\n",
       "      <td>18.600000</td>\n",
       "      <td>43.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.714</td>\n",
       "      <td>0.407</td>\n",
       "      <td>31.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725600</td>\n",
       "      <td>0.326067</td>\n",
       "      <td>21.066667</td>\n",
       "      <td>44.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.452733</td>\n",
       "      <td>0.734200</td>\n",
       "      <td>0.330867</td>\n",
       "      <td>19.800000</td>\n",
       "      <td>42.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   G_home  G_away  W_PCT_home  W_PCT_prev_home  FG_PCT_home  FT_PCT_home  \\\n",
       "0    82.0    82.0       0.707            0.768        0.471        0.692   \n",
       "1    82.0    82.0       0.512            0.549        0.421        0.600   \n",
       "2    82.0    82.0       0.512            0.415        0.416        0.684   \n",
       "3    82.0    82.0       0.610            0.610        0.364        0.600   \n",
       "4    82.0    82.0       0.549            0.537        0.462        0.714   \n",
       "\n",
       "   FG3_PCT_home  AST_home  REB_home  W_PCT_away  ...  FT_PCT_home_15g  \\\n",
       "0         0.250      21.0      40.0       0.390  ...         0.716933   \n",
       "1         0.250      18.0      37.0       0.634  ...         0.707267   \n",
       "2         0.261      19.0      37.0       0.622  ...         0.749400   \n",
       "3         0.250      13.0      47.0       0.817  ...         0.727933   \n",
       "4         0.407      31.0      50.0       0.378  ...         0.725600   \n",
       "\n",
       "   FG3_PCT_home_15g  AST_home_15g  REB_home_15g  WIN_PRCT_away_15g  \\\n",
       "0          0.400533     20.000000     41.266667           0.466667   \n",
       "1          0.356267     20.466667     43.800000           0.466667   \n",
       "2          0.343067     19.133333     39.600000           0.466667   \n",
       "3          0.309867     17.000000     42.600000           0.533333   \n",
       "4          0.326067     21.066667     44.133333           0.133333   \n",
       "\n",
       "   FG_PCT_away_15g  FT_PCT_away_15g  FG3_PCT_away_15g  AST_away_15g  \\\n",
       "0         0.443267         0.779800          0.372867     18.133333   \n",
       "1         0.447200         0.774400          0.368600     20.600000   \n",
       "2         0.448267         0.721467          0.338667     21.600000   \n",
       "3         0.449867         0.800667          0.346667     18.600000   \n",
       "4         0.452733         0.734200          0.330867     19.800000   \n",
       "\n",
       "   REB_away_15g  \n",
       "0     38.000000  \n",
       "1     41.200000  \n",
       "2     43.400000  \n",
       "3     43.066667  \n",
       "4     42.400000  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This feature will be used for the prediction of a classifier which takes those fetures as inputs\n",
    "features = [\n",
    "    'G_home', 'G_away',\n",
    "    'W_PCT_home', 'W_PCT_prev_home', 'FG_PCT_home', 'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home',\n",
    "    'W_PCT_away', 'W_PCT_prev_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away',\n",
    "    'WIN_PRCT_home_2g', 'FG_PCT_home_2g', 'FT_PCT_home_2g', 'FG3_PCT_home_2g', 'AST_home_2g', 'REB_home_2g',\n",
    "    'WIN_PRCT_away_2g', 'FG_PCT_away_2g', 'FT_PCT_away_2g', 'FG3_PCT_away_2g', 'AST_away_2g', 'REB_away_2g',\n",
    "    'WIN_PRCT_home_4g', 'FG_PCT_home_4g', 'FT_PCT_home_4g', 'FG3_PCT_home_4g', 'AST_home_4g', 'REB_home_4g',\n",
    "    'WIN_PRCT_away_4g', 'FG_PCT_away_4g', 'FT_PCT_away_4g', 'FG3_PCT_away_4g', 'AST_away_4g', 'REB_away_4g',\n",
    "    'WIN_PRCT_home_6g', 'FG_PCT_home_6g', 'FT_PCT_home_6g', 'FG3_PCT_home_6g', 'AST_home_6g', 'REB_home_6g',\n",
    "    'WIN_PRCT_away_6g', 'FG_PCT_away_6g', 'FT_PCT_away_6g', 'FG3_PCT_away_6g', 'AST_away_6g', 'REB_away_6g',\n",
    "    'WIN_PRCT_home_8g', 'FG_PCT_home_8g', 'FT_PCT_home_8g', 'FG3_PCT_home_8g', 'AST_home_8g', 'REB_home_8g',\n",
    "    'WIN_PRCT_away_8g', 'FG_PCT_away_8g', 'FT_PCT_away_8g', 'FG3_PCT_away_8g', 'AST_away_8g', 'REB_away_8g',\n",
    "    'WIN_PRCT_home_10g', 'FG_PCT_home_10g', 'FT_PCT_home_10g', 'FG3_PCT_home_10g', 'AST_home_10g', 'REB_home_10g',\n",
    "    'WIN_PRCT_away_10g', 'FG_PCT_away_10g', 'FT_PCT_away_10g', 'FG3_PCT_away_10g', 'AST_away_10g', 'REB_away_10g',\n",
    "    'WIN_PRCT_home_15g', 'FG_PCT_home_15g', 'FT_PCT_home_15g', 'FG3_PCT_home_15g', 'AST_home_15g', 'REB_home_15g',\n",
    "    'WIN_PRCT_away_15g', 'FG_PCT_away_15g', 'FT_PCT_away_15g', 'FG3_PCT_away_15g', 'AST_away_15g', 'REB_away_15g'\n",
    "    ]\n",
    "\n",
    "# Check selected features in dataframe\n",
    "X = df[features]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf355c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "Name: HOME_TEAM_WINS_x, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the target\n",
    "Y = df['HOME_TEAM_WINS_x']\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d657763",
   "metadata": {},
   "source": [
    "---\n",
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a1d30c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Shape : (14377, 88) | Y Train Shape : (14377,) | X Test Shape : (6162, 88) | Y Test Shape : (6162,)\n"
     ]
    }
   ],
   "source": [
    "# Apply Train test split on them\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, \n",
    "    Y, \n",
    "    train_size=0.7, random_state=0, stratify=df['HOME_TEAM_WINS_x'])\n",
    "\n",
    "print(f\"X Train Shape : {X_train.shape} | Y Train Shape : {Y_train.shape} | X Test Shape : {X_test.shape} | Y Test Shape : {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ace78ef",
   "metadata": {},
   "source": [
    "---\n",
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e436708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83.86, 85.31, 69.8]\n",
      "CPU times: user 12min 47s, sys: 1.5 s, total: 12min 49s\n",
      "Wall time: 4min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = [RandomForestClassifier(), LogisticRegression(max_iter=5000), SGDClassifier()]\n",
    "scores = []\n",
    "\n",
    "for m in models:\n",
    "    s = cross_val_score(m, X, Y, cv=10, scoring='accuracy')\n",
    "    scores.append(round(np.mean(s)* 100 ,2))\n",
    "    \n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995893e4",
   "metadata": {},
   "source": [
    "---\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d9934cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50 s, sys: 944 ms, total: 50.9 s\n",
      "Wall time: 13.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G_home</th>\n",
       "      <td>0.000885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_away</th>\n",
       "      <td>-0.000213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W_PCT_home</th>\n",
       "      <td>1.549886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W_PCT_prev_home</th>\n",
       "      <td>0.707207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <td>16.450645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG_PCT_away_15g</th>\n",
       "      <td>0.251144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT_PCT_away_15g</th>\n",
       "      <td>0.241747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FG3_PCT_away_15g</th>\n",
       "      <td>0.080143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST_away_15g</th>\n",
       "      <td>0.078505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REB_away_15g</th>\n",
       "      <td>0.028404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       coef\n",
       "G_home             0.000885\n",
       "G_away            -0.000213\n",
       "W_PCT_home         1.549886\n",
       "W_PCT_prev_home    0.707207\n",
       "FG_PCT_home       16.450645\n",
       "...                     ...\n",
       "FG_PCT_away_15g    0.251144\n",
       "FT_PCT_away_15g    0.241747\n",
       "FG3_PCT_away_15g   0.080143\n",
       "AST_away_15g       0.078505\n",
       "REB_away_15g       0.028404\n",
       "\n",
       "[88 rows x 1 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(max_iter=5000)\n",
    "\n",
    "# Fit training set to the logistic regression\n",
    "model = lr.fit(X_train,Y_train)\n",
    "\n",
    "# Constante\n",
    "pd.DataFrame(model.coef_[0],index=X_train.columns,columns=[\"coef\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40441507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0635823])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constant\n",
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eee2b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Hyperparameters Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5508ae22",
   "metadata": {},
   "source": [
    "#### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5a5e9f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.838 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.835 total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.831 total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.839 total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=0.1, penalty=l1, solver=saga;, score=0.832 total time= 2.0min\n",
      "[CV 1/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.862 total time=  13.1s\n",
      "[CV 2/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.860 total time=   9.6s\n",
      "[CV 3/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.852 total time=   9.8s\n",
      "[CV 4/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.853 total time=   8.0s\n",
      "[CV 5/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.848 total time=   8.8s\n",
      "[CV 1/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.826 total time= 1.5min\n",
      "[CV 2/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.826 total time= 1.6min\n",
      "[CV 3/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.816 total time= 1.6min\n",
      "[CV 4/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.830 total time= 1.6min\n",
      "[CV 5/5] END ....C=0.1, penalty=l2, solver=saga;, score=0.823 total time= 1.5min\n",
      "[CV 1/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.831 total time=   2.2s\n",
      "[CV 2/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.831 total time=   2.2s\n",
      "[CV 3/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.823 total time=   2.2s\n",
      "[CV 4/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.833 total time=   2.4s\n",
      "[CV 5/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.827 total time=   2.4s\n",
      "[CV 1/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.831 total time=   9.8s\n",
      "[CV 2/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.831 total time=  10.4s\n",
      "[CV 3/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.823 total time=   9.6s\n",
      "[CV 4/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.833 total time=   9.1s\n",
      "[CV 5/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.828 total time=   9.0s\n",
      "[CV 1/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.828 total time=  40.6s\n",
      "[CV 2/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.828 total time=  41.4s\n",
      "[CV 3/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.819 total time=  41.9s\n",
      "[CV 4/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.831 total time=  39.5s\n",
      "[CV 5/5] END .....C=0.1, penalty=l2, solver=sag;, score=0.825 total time=  42.5s\n",
      "[CV 1/5] END C=0.1, penalty=l2, solver=newton-cg;, score=0.830 total time=   3.4s\n",
      "[CV 2/5] END C=0.1, penalty=l2, solver=newton-cg;, score=0.831 total time=   3.4s\n",
      "[CV 3/5] END C=0.1, penalty=l2, solver=newton-cg;, score=0.823 total time=   2.9s\n",
      "[CV 4/5] END C=0.1, penalty=l2, solver=newton-cg;, score=0.833 total time=   2.7s\n",
      "[CV 5/5] END C=0.1, penalty=l2, solver=newton-cg;, score=0.827 total time=   2.8s\n",
      "[CV 1/5] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=0.1, penalty=none, solver=saga;, score=0.837 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=0.1, penalty=none, solver=saga;, score=0.838 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=0.1, penalty=none, solver=saga;, score=0.835 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=0.1, penalty=none, solver=saga;, score=0.841 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=0.1, penalty=none, solver=saga;, score=0.835 total time= 1.6min\n",
      "[CV 1/5] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=0.1, penalty=none, solver=lbfgs;, score=0.861 total time=  17.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=0.1, penalty=none, solver=lbfgs;, score=0.861 total time=  18.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=0.1, penalty=none, solver=lbfgs;, score=0.852 total time=  17.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=0.1, penalty=none, solver=lbfgs;, score=0.853 total time=  19.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=0.1, penalty=none, solver=lbfgs;, score=0.848 total time=  16.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=0.1, penalty=none, solver=sag;, score=0.852 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=0.1, penalty=none, solver=sag;, score=0.850 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.1, penalty=none, solver=sag;, score=0.844 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=0.1, penalty=none, solver=sag;, score=0.848 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=0.1, penalty=none, solver=sag;, score=0.837 total time= 1.2min\n",
      "[CV 1/5] END C=0.1, penalty=none, solver=newton-cg;, score=0.861 total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/scipy/optimize/_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/usr/lib64/python3.10/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.1, penalty=none, solver=newton-cg;, score=0.861 total time=  13.5s\n",
      "[CV 3/5] END C=0.1, penalty=none, solver=newton-cg;, score=0.852 total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.1, penalty=none, solver=newton-cg;, score=0.856 total time=  10.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.1, penalty=none, solver=newton-cg;, score=0.845 total time=  14.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=1.0, penalty=l1, solver=saga;, score=0.837 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=1.0, penalty=l1, solver=saga;, score=0.838 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=1.0, penalty=l1, solver=saga;, score=0.835 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=1.0, penalty=l1, solver=saga;, score=0.842 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=1.0, penalty=l1, solver=saga;, score=0.834 total time= 2.0min\n",
      "[CV 1/5] END C=1.0, penalty=l1, solver=liblinear;, score=0.862 total time=  19.7s\n",
      "[CV 2/5] END C=1.0, penalty=l1, solver=liblinear;, score=0.862 total time=  17.8s\n",
      "[CV 3/5] END C=1.0, penalty=l1, solver=liblinear;, score=0.852 total time=  17.5s\n",
      "[CV 4/5] END C=1.0, penalty=l1, solver=liblinear;, score=0.853 total time=  14.2s\n",
      "[CV 5/5] END C=1.0, penalty=l1, solver=liblinear;, score=0.847 total time=  14.3s\n",
      "[CV 1/5] END .....C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=1.0, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .......C=1.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......C=1.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......C=1.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......C=1.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......C=1.0, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=1.0, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=1.0, penalty=l2, solver=saga;, score=0.839 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=1.0, penalty=l2, solver=saga;, score=0.838 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=1.0, penalty=l2, solver=saga;, score=0.835 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=1.0, penalty=l2, solver=saga;, score=0.840 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=1.0, penalty=l2, solver=saga;, score=0.834 total time= 1.9min\n",
      "[CV 1/5] END C=1.0, penalty=l2, solver=liblinear;, score=0.861 total time=   3.8s\n",
      "[CV 2/5] END C=1.0, penalty=l2, solver=liblinear;, score=0.858 total time=   4.8s\n",
      "[CV 3/5] END C=1.0, penalty=l2, solver=liblinear;, score=0.851 total time=   4.6s\n",
      "[CV 4/5] END C=1.0, penalty=l2, solver=liblinear;, score=0.854 total time=   4.3s\n",
      "[CV 5/5] END C=1.0, penalty=l2, solver=liblinear;, score=0.844 total time=   3.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.861 total time=  17.4s\n",
      "[CV 2/5] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.857 total time=  15.8s\n",
      "[CV 3/5] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.851 total time=  18.0s\n",
      "[CV 4/5] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.852 total time=  17.0s\n",
      "[CV 5/5] END ...C=1.0, penalty=l2, solver=lbfgs;, score=0.844 total time=  15.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .....C=1.0, penalty=l2, solver=sag;, score=0.850 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .....C=1.0, penalty=l2, solver=sag;, score=0.847 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .....C=1.0, penalty=l2, solver=sag;, score=0.844 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .....C=1.0, penalty=l2, solver=sag;, score=0.847 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .....C=1.0, penalty=l2, solver=sag;, score=0.837 total time= 1.1min\n",
      "[CV 1/5] END C=1.0, penalty=l2, solver=newton-cg;, score=0.861 total time=   3.8s\n",
      "[CV 2/5] END C=1.0, penalty=l2, solver=newton-cg;, score=0.859 total time=   4.1s\n",
      "[CV 3/5] END C=1.0, penalty=l2, solver=newton-cg;, score=0.850 total time=   4.2s\n",
      "[CV 4/5] END C=1.0, penalty=l2, solver=newton-cg;, score=0.852 total time=   4.4s\n",
      "[CV 5/5] END C=1.0, penalty=l2, solver=newton-cg;, score=0.845 total time=   4.6s\n",
      "[CV 1/5] END C=1.0, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=1.0, penalty=none, solver=saga;, score=0.837 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=1.0, penalty=none, solver=saga;, score=0.838 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=1.0, penalty=none, solver=saga;, score=0.835 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=1.0, penalty=none, solver=saga;, score=0.841 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=1.0, penalty=none, solver=saga;, score=0.835 total time= 1.6min\n",
      "[CV 1/5] END C=1.0, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.0, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.0, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.0, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.0, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=1.0, penalty=none, solver=lbfgs;, score=0.861 total time=  17.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=1.0, penalty=none, solver=lbfgs;, score=0.861 total time=  20.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=1.0, penalty=none, solver=lbfgs;, score=0.852 total time=  18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=1.0, penalty=none, solver=lbfgs;, score=0.853 total time=  16.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=1.0, penalty=none, solver=lbfgs;, score=0.848 total time=  15.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=1.0, penalty=none, solver=sag;, score=0.852 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=1.0, penalty=none, solver=sag;, score=0.850 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=1.0, penalty=none, solver=sag;, score=0.844 total time= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=1.0, penalty=none, solver=sag;, score=0.848 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=1.0, penalty=none, solver=sag;, score=0.837 total time= 1.1min\n",
      "[CV 1/5] END C=1.0, penalty=none, solver=newton-cg;, score=0.861 total time=  16.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/scipy/optimize/_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/usr/lib64/python3.10/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.0, penalty=none, solver=newton-cg;, score=0.861 total time=  16.7s\n",
      "[CV 3/5] END C=1.0, penalty=none, solver=newton-cg;, score=0.852 total time=  12.0s\n",
      "[CV 4/5] END C=1.0, penalty=none, solver=newton-cg;, score=0.856 total time=  11.6s\n",
      "[CV 5/5] END C=1.0, penalty=none, solver=newton-cg;, score=0.845 total time=  13.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .....C=10, penalty=l1, solver=saga;, score=0.837 total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .....C=10, penalty=l1, solver=saga;, score=0.838 total time= 2.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .....C=10, penalty=l1, solver=saga;, score=0.835 total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .....C=10, penalty=l1, solver=saga;, score=0.841 total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .....C=10, penalty=l1, solver=saga;, score=0.835 total time= 2.1min\n",
      "[CV 1/5] END C=10, penalty=l1, solver=liblinear;, score=0.862 total time=  27.9s\n",
      "[CV 2/5] END C=10, penalty=l1, solver=liblinear;, score=0.859 total time=  28.8s\n",
      "[CV 3/5] END C=10, penalty=l1, solver=liblinear;, score=0.852 total time=  27.4s\n",
      "[CV 4/5] END C=10, penalty=l1, solver=liblinear;, score=0.855 total time=  21.4s\n",
      "[CV 5/5] END C=10, penalty=l1, solver=liblinear;, score=0.847 total time=  21.4s\n",
      "[CV 1/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .....C=10, penalty=l2, solver=saga;, score=0.837 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .....C=10, penalty=l2, solver=saga;, score=0.838 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .....C=10, penalty=l2, solver=saga;, score=0.835 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .....C=10, penalty=l2, solver=saga;, score=0.841 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .....C=10, penalty=l2, solver=saga;, score=0.835 total time= 1.9min\n",
      "[CV 1/5] END C=10, penalty=l2, solver=liblinear;, score=0.863 total time=   4.3s\n",
      "[CV 2/5] END C=10, penalty=l2, solver=liblinear;, score=0.861 total time=   3.9s\n",
      "[CV 3/5] END C=10, penalty=l2, solver=liblinear;, score=0.851 total time=   4.5s\n",
      "[CV 4/5] END C=10, penalty=l2, solver=liblinear;, score=0.854 total time=   4.4s\n",
      "[CV 5/5] END C=10, penalty=l2, solver=liblinear;, score=0.849 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.864 total time=  16.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.861 total time=  17.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.852 total time=  17.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.854 total time=  17.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.849 total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ......C=10, penalty=l2, solver=sag;, score=0.852 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ......C=10, penalty=l2, solver=sag;, score=0.850 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ......C=10, penalty=l2, solver=sag;, score=0.844 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ......C=10, penalty=l2, solver=sag;, score=0.848 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ......C=10, penalty=l2, solver=sag;, score=0.838 total time= 1.1min\n",
      "[CV 1/5] END C=10, penalty=l2, solver=newton-cg;, score=0.864 total time=   5.7s\n",
      "[CV 2/5] END C=10, penalty=l2, solver=newton-cg;, score=0.861 total time=   6.8s\n",
      "[CV 3/5] END C=10, penalty=l2, solver=newton-cg;, score=0.852 total time=   6.8s\n",
      "[CV 4/5] END C=10, penalty=l2, solver=newton-cg;, score=0.854 total time=   5.7s\n",
      "[CV 5/5] END C=10, penalty=l2, solver=newton-cg;, score=0.847 total time=   6.8s\n",
      "[CV 1/5] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=10, penalty=none, solver=saga;, score=0.837 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=10, penalty=none, solver=saga;, score=0.838 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=10, penalty=none, solver=saga;, score=0.835 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=10, penalty=none, solver=saga;, score=0.841 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=10, penalty=none, solver=saga;, score=0.835 total time= 1.5min\n",
      "[CV 1/5] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=10, penalty=none, solver=lbfgs;, score=0.861 total time=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=10, penalty=none, solver=lbfgs;, score=0.861 total time=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=10, penalty=none, solver=lbfgs;, score=0.852 total time=  16.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=10, penalty=none, solver=lbfgs;, score=0.853 total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=10, penalty=none, solver=lbfgs;, score=0.848 total time=  16.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=10, penalty=none, solver=sag;, score=0.852 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=10, penalty=none, solver=sag;, score=0.850 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=10, penalty=none, solver=sag;, score=0.844 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=10, penalty=none, solver=sag;, score=0.848 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=10, penalty=none, solver=sag;, score=0.837 total time= 1.1min\n",
      "[CV 1/5] END C=10, penalty=none, solver=newton-cg;, score=0.861 total time=  13.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/scipy/optimize/_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/usr/lib64/python3.10/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, penalty=none, solver=newton-cg;, score=0.861 total time=  13.0s\n",
      "[CV 3/5] END C=10, penalty=none, solver=newton-cg;, score=0.852 total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10, penalty=none, solver=newton-cg;, score=0.856 total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10, penalty=none, solver=newton-cg;, score=0.845 total time=  12.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=100, penalty=l1, solver=saga;, score=0.837 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=100, penalty=l1, solver=saga;, score=0.838 total time= 2.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=100, penalty=l1, solver=saga;, score=0.835 total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=100, penalty=l1, solver=saga;, score=0.841 total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=100, penalty=l1, solver=saga;, score=0.835 total time= 2.0min\n",
      "[CV 1/5] END C=100, penalty=l1, solver=liblinear;, score=0.861 total time=  25.2s\n",
      "[CV 2/5] END C=100, penalty=l1, solver=liblinear;, score=0.861 total time=  35.6s\n",
      "[CV 3/5] END C=100, penalty=l1, solver=liblinear;, score=0.852 total time=  31.0s\n",
      "[CV 4/5] END C=100, penalty=l1, solver=liblinear;, score=0.855 total time=  21.1s\n",
      "[CV 5/5] END C=100, penalty=l1, solver=liblinear;, score=0.846 total time=  23.3s\n",
      "[CV 1/5] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ....C=100, penalty=l2, solver=saga;, score=0.837 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ....C=100, penalty=l2, solver=saga;, score=0.838 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ....C=100, penalty=l2, solver=saga;, score=0.835 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ....C=100, penalty=l2, solver=saga;, score=0.841 total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ....C=100, penalty=l2, solver=saga;, score=0.835 total time= 1.7min\n",
      "[CV 1/5] END C=100, penalty=l2, solver=liblinear;, score=0.863 total time=   4.3s\n",
      "[CV 2/5] END C=100, penalty=l2, solver=liblinear;, score=0.861 total time=   4.7s\n",
      "[CV 3/5] END C=100, penalty=l2, solver=liblinear;, score=0.852 total time=   4.4s\n",
      "[CV 4/5] END C=100, penalty=l2, solver=liblinear;, score=0.854 total time=   4.3s\n",
      "[CV 5/5] END C=100, penalty=l2, solver=liblinear;, score=0.847 total time=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.864 total time=  16.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.861 total time=  16.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.852 total time=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.853 total time=  16.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=100, penalty=l2, solver=lbfgs;, score=0.848 total time=  17.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .....C=100, penalty=l2, solver=sag;, score=0.852 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .....C=100, penalty=l2, solver=sag;, score=0.850 total time= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .....C=100, penalty=l2, solver=sag;, score=0.844 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .....C=100, penalty=l2, solver=sag;, score=0.848 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .....C=100, penalty=l2, solver=sag;, score=0.837 total time= 1.1min\n",
      "[CV 1/5] END C=100, penalty=l2, solver=newton-cg;, score=0.862 total time=  10.4s\n",
      "[CV 2/5] END C=100, penalty=l2, solver=newton-cg;, score=0.860 total time=  11.1s\n",
      "[CV 3/5] END C=100, penalty=l2, solver=newton-cg;, score=0.852 total time=   9.2s\n",
      "[CV 4/5] END C=100, penalty=l2, solver=newton-cg;, score=0.855 total time=  11.2s\n",
      "[CV 5/5] END C=100, penalty=l2, solver=newton-cg;, score=0.846 total time=  10.8s\n",
      "[CV 1/5] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=100, penalty=none, solver=saga;, score=0.837 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=100, penalty=none, solver=saga;, score=0.838 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=100, penalty=none, solver=saga;, score=0.835 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=100, penalty=none, solver=saga;, score=0.841 total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=100, penalty=none, solver=saga;, score=0.835 total time= 1.5min\n",
      "[CV 1/5] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END .C=100, penalty=none, solver=lbfgs;, score=0.861 total time=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .C=100, penalty=none, solver=lbfgs;, score=0.861 total time=  15.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END .C=100, penalty=none, solver=lbfgs;, score=0.852 total time=  15.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .C=100, penalty=none, solver=lbfgs;, score=0.853 total time=  16.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END .C=100, penalty=none, solver=lbfgs;, score=0.848 total time=  14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ...C=100, penalty=none, solver=sag;, score=0.852 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ...C=100, penalty=none, solver=sag;, score=0.850 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=100, penalty=none, solver=sag;, score=0.844 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=100, penalty=none, solver=sag;, score=0.848 total time= 1.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...C=100, penalty=none, solver=sag;, score=0.837 total time= 1.1min\n",
      "[CV 1/5] END C=100, penalty=none, solver=newton-cg;, score=0.861 total time=  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/usr/lib64/python3.10/site-packages/scipy/optimize/_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/usr/lib64/python3.10/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=100, penalty=none, solver=newton-cg;, score=0.861 total time=  13.7s\n",
      "[CV 3/5] END C=100, penalty=none, solver=newton-cg;, score=0.852 total time=  12.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=100, penalty=none, solver=newton-cg;, score=0.856 total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=100, penalty=none, solver=newton-cg;, score=0.845 total time=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "180 fits failed out of a total of 400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/lib64/python3.10/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.83504539 0.85505588        nan        nan        nan 0.82433415\n",
      " 0.82891075 0.82910553 0.82647641 0.82891075        nan        nan\n",
      "        nan        nan        nan 0.8375285         nan 0.85500721\n",
      " 0.84619461 0.854861   0.83718763 0.8552506         nan        nan\n",
      "        nan 0.83713896 0.85359513 0.85305959 0.84512353 0.85349782\n",
      "        nan        nan        nan        nan        nan 0.8375285\n",
      "        nan 0.85500721 0.84619461 0.854861   0.83738243 0.85510453\n",
      "        nan        nan        nan 0.83738242 0.85564018 0.8561757\n",
      " 0.84624331 0.85544531        nan        nan        nan        nan\n",
      "        nan 0.8375285         nan 0.85500721 0.84619461 0.854861\n",
      " 0.8375285  0.85515318        nan        nan        nan 0.8375285\n",
      " 0.85529926 0.85568882 0.84619461 0.85510447        nan        nan\n",
      "        nan        nan        nan 0.8375285         nan 0.85500721\n",
      " 0.84619461 0.854861  ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 38min 29s, sys: 11.1 s, total: 3h 38min 40s\n",
      "Wall time: 2h 53min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.10/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=4000),\n",
       "             param_grid=[{'C': [0.1, 1.0, 10, 100],\n",
       "                          'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                          'solver': ['saga', 'liblinear', 'lbfgs', 'sag',\n",
       "                                     'newton-cg']}],\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "parametres = [{\n",
    "    'penalty':['l1','l2', 'elasticnet', 'none'],\n",
    "    'C':[0.1,1.0,10, 100], \n",
    "    'solver' : ['saga', 'liblinear', 'lbfgs', 'sag', 'newton-cg']\n",
    "}]\n",
    "\n",
    "gs = GridSearchCV(estimator=model,param_grid=parametres,scoring='accuracy', refit=True, verbose=3)\n",
    "gs.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d1557b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               params  mean_test_score\n",
      "0       {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}         0.835045\n",
      "1   {'C': 0.1, 'penalty': 'l1', 'solver': 'libline...         0.855056\n",
      "2      {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'}              NaN\n",
      "3        {'C': 0.1, 'penalty': 'l1', 'solver': 'sag'}              NaN\n",
      "4   {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-...              NaN\n",
      "..                                                ...              ...\n",
      "75    {'C': 100, 'penalty': 'none', 'solver': 'saga'}         0.837529\n",
      "76  {'C': 100, 'penalty': 'none', 'solver': 'libli...              NaN\n",
      "77   {'C': 100, 'penalty': 'none', 'solver': 'lbfgs'}         0.855007\n",
      "78     {'C': 100, 'penalty': 'none', 'solver': 'sag'}         0.846195\n",
      "79  {'C': 100, 'penalty': 'none', 'solver': 'newto...         0.854861\n",
      "\n",
      "[80 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(gs.cv_results_).loc[:,['params','mean_test_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33539c40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7eb59a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841808e7",
   "metadata": {},
   "source": [
    "---\n",
    "#### Best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e57403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8561756959464792\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689bc8ca",
   "metadata": {},
   "source": [
    "---\n",
    "#### Prediction with the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2de0e8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      2558\n",
      "           1       0.88      0.89      0.88      3604\n",
      "\n",
      "    accuracy                           0.86      6162\n",
      "   macro avg       0.86      0.86      0.86      6162\n",
      "weighted avg       0.86      0.86      0.86      6162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pred_best = gs.predict(X_test)\n",
    "pred_best = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "# Performance mesures\n",
    "print(metrics.classification_report(Y_test,pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d889f85",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36734ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2101  457]\n",
      " [ 401 3203]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(Y_test,pred_best)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2181068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(cm/np.sum(cm), annot=True, \n",
    "            fmt='.2%', cmap='Oranges')\n",
    "\n",
    "ax.set_title('Nba game confusion matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicte the Winner')\n",
    "ax.set_ylabel('Actual Values');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394a259",
   "metadata": {},
   "source": [
    "#### Accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4e487a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is up to :  86.08 %\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(Y_test, pred_best)\n",
    "print(\"The accuracy score is up to : \",round(acc * 100 ,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac82f7d3",
   "metadata": {},
   "source": [
    "---\n",
    "## Optimized Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c882efd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "olr = LogisticRegression(max_iter = 7000, C = 10, penalty = 'l2', solver = 'lbfgs')\n",
    "\n",
    "# Fit training set to the logistic regression\n",
    "omodel = olr.fit(X_train,Y_train)\n",
    "\n",
    "# Constante\n",
    "pd.DataFrame(omodel.coef_[0],index=X_train.columns,columns=[\"coef\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b69d899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.44844878])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omodel.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5c208",
   "metadata": {},
   "source": [
    "---\n",
    "### Build Optimized Y pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dfb0424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OY_pred = omodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795be7b2",
   "metadata": {},
   "source": [
    "---\n",
    "### Display Optimized confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ed65ea44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2092  466]\n",
      " [ 412 3192]]\n"
     ]
    }
   ],
   "source": [
    "cm2 = metrics.confusion_matrix(Y_test,OY_pred)\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c3488894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAFACAYAAAB6LV2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqkklEQVR4nO3dd5hV9bXG8e87BRlAVBREEBu22FuMRlETSyzBEht2YsFuNNFoormiMTHBJNcWC5ZYLrEr9oq9gwoWREVEwd4pUmaGdf/Ye/QAU87AnLKZ9/M8+2HX3177zLDmd9ZuigjMzKy8VZQ6ADMza5mTtZlZBjhZm5llgJO1mVkGOFmbmWWAk7WZWQY4WZcJSSFp1VLHkTVK/EfS15JeXIh2+kl6qy1jKxVJK0iaJqmy1LFY23GyLgJJEyV9KqlzzrzDJT1ewrAWFVsC2wPLR8SmC9pIRDwVEWu0XViFkf4ubdfcOhHxQUR0iYj6YsVlhedkXTxVwG9KHcQiaEVgYkRML3Ug5UBSValjsMJwsi6e84CTJS3ZzDo7S5og6QtJ50mqAJDUV9Kjkr5Mlw1rrh1JO0h6S9K3ki6R9ISkw/NpK+25nSLpVUnTJV0laVlJ90uaKukRSUvlrL+ZpGclfSNpjKRtmomrj6TbJX2e7v/idH6FpDMkvS/pM0nXSVoiXbZSWiI6RNIHacynp8sOA64ENk+/9p8laaCkp+fZ7/clJkk7SxqbHsuHkk5O528jaXLONj+S9Hh6XG9I2jVn2TWS/i3p3rSdFyT1beKYG+L/taRJabnmKEk/Tj/jbxo+h5Z+PpKuB1YA7k6P9/c57R8m6QPg0Zx5VZK6SZosqX/aRhdJ4yUd3NTPycpURHgo8ABMBLYDbgfOSecdDjyes04AjwHdSP5Dvg0cni5bleSr/mJAd+BJ4Pwm9rUMMAX4FT/05mvzbSuN9XlgWaA38BnwMrBhus2jwJnpur2BL4GdSf7wb59Od28krkpgDPC/QGegI7BluuxQYDywCtAl/ZyuT5etlH42VwA1wPrALOBH6fKBwNM5+5lrOuezXTUd/xjol44vBWyUjm8DTE7Hq9N4/gh0AH4OTAXWSJdfA3wFbJp+xsOAG5v4eTTEf1l6zDsAM4HhQI+cz3jrVvx8tmuk/evSz7UmZ15Vus4OwCfp/q4Abi31/wkPC5BHSh1Aexj4IVmvA3yb/idsLFnvmDN9DDCiifZ2B15pYtnBwHM50wImkSbrltpKYz0gZ/o24NKc6eOB4en4qaRJNWf5g8Ahjexnc+DzhgQyz7IRwDE502uQ/IGpykk8y+csfxEYkI4PpHXJ+gPgSKDrPOtsww/Jul+a3Cpylt8ADE7HrwGuzFm2MzCuic+3If7eOfO+BPad5zM+sRU/n8aS9SqNzKvKmXcR8BrwEbB0qf9PeGj94DJIEUXE68A9wGlNrDIpZ/x9oBeApB6Sbky/tk8B/o+kB92YXrntRPI/NffrfT5tfZozPqOR6S7p+IrA3ulX+W8kfUNywm+5RuLqA7wfEXVNxPx+zvT7JIl62Zx5n+SMf5cTQ2vtSZJc30/LQ5s3Ec+kiJgzT0y9FyKevD7TVv6sc01qYflQks7CfyLiyzzaszLjZF18ZwJHMPd//AZ9csZXIOkFAZxL0lNaLyK6AgeS9Jgb8zGwfMOEJOVOt7Ktlkwi6VkvmTN0joi/NbHuCmr8BNhHJIm/wQpAHXMntHxNBzo1TEjqmbswIkZGxG4kJYHhwM1NxNNH6TmDnJg+XIB4Wquln09Tj8ls8vGZSi7hu5ykVHK0fIloJjlZF1lEjAduAk5oZPEpkpaS1Iek1nxTOn9xYBrwjaTewCnN7OJeYF1Ju6eJ8VggN2G1pq2W/B/QX9IvJFVK6pieqFu+kXVfJPlD8jdJndN1t0iX3QCcJGllSV2AvwI3NdELb8kYYG1JG0jqCAxuWCCpg6QDJC0REbUktf3GLm97gSTp/15StZKTpv2BGxcgntZq6efzKUltvzX+mP57KPAP4Dr5GuzMcbIujbNJTgbN607gJWA0SdK9Kp1/FrARSb37XpITcI2KiC+AvYEhJLXRtYBRJCflWtVWSyJiErAbSTL4nKT3fAqN/F5Fcs1vf5ITaB+QlGb2TRdfDVxPcjLtPZITcMcvYExvk3y+jwDvAE/Ps8pBwMS0xHAUSc913jZmA7sCOwFfAJcAB0fEuAWJqZVa+vmcC5yRlp1ObqkxSRsDvyWJvx74O0kvvKlSnJUpJSVNW1SlX+Unk5w0fKzU8ZjZgnHPehGUliWWlLQYSa9XJJfjmVlGOVkvmjYH3iX5Ct8f2D0iZpQ2JDNbGC6DmJllgHvWZmYZ4GRtZpYBTtZmZhngZG1mlgFO1mZmGeBkbWaWAU7WZmYZ4GRtZpYBTtZmZhngZG1mlgFO1mZmGeBkbWaWAU7WZmYZ4GRtZpYBTtZmZhngZG1mlgFO1mZmGeBkbWaWAU7WZmYZ4GRtZpYBTtZmZhngZG1mlgFO1mZmGeBkbWaWAU7WZmYZ4GRtZpYBTtZmZhngZG1mlgFO1mZmGeBkbWaWAU7WZmYZ4GRtZpYBVaUOoCnTTuwdpY7Byk+Xc14qdQhWjrr01MI2MXjN6rxzzuBxtQu9v9Yq22RtZlZMFUVPv63jZG1mRvnXhJ2szcwAuWdtZlb+yjxXl33P38ysKKT8h5bb0o6S3pI0XtJpjSzfRtK3kkanw/+01KZ71mZmtF3PVVIl8G9ge2AyMFLSXRExdp5Vn4qIXxY7PjOzTKtQ/kMLNgXGR8SEiJgN3AjsttDxLWwDZmaLgtaUQSQNkjQqZxiU01RvYFLO9OR03rw2lzRG0v2S1m4pPpdBzMxo3QnGiBgKDG1FU/PecPMysGJETJO0MzAcWK25fbpnbWZGm5ZBJgN9cqaXBz7KXSEipkTEtHT8PqBa0jLNxtfqIzIzWwSpFUMLRgKrSVpZUgdgAHDXXPuSekrJdSWSNiXJxV8216jLIGZmtN1NMRFRJ+k44EGgErg6It6QdFS6/DJgL+BoSXXADGBARDT7bBInazMzoFJt9+y4tLRx3zzzLssZvxi4uDVtOlmbmVH+dzA6WZuZ4WRtZpYJfpCTmVkGlHmudrI2MwOoLPNs7WRtZobLIGZmmVDmudrJ2swM/A5GM7NMKPNc7WRtZgauWZuZZYLLIGZmGVDujyB1sjYzw2UQM7NMKPNc7WRtZgauWZuZZYJvNzczywCfYDQzywCfYDQzywD3rM3MMsA9azOzDKhowxfmFoKTtZkZvhrEzCwTXLM2M8sA16zNzDLAPWszswzw7eZmZhngMoiZWQb4ahAzswxwzdrMLANcszYzy4Ayz9VO1mZm4J61mVkm+ASjmVkG+EFOZmYZUOYdaydrMzNwzbp9q1qMmuNvg6rFoKKS+jH3MvuBf9Jhp1OoXHcHiCCmfsGs/55ETPl0vs2rtzqMqs33B0Td8/+l9okrAeiw42+p2mx/YvpXAMy+52/Uv/koFStvwmJ7nwt1s5l53bHEFxOhpisdD7mUmZcdUMQDt3xNmPgBJ/3hrO+nJ334ESccdSgD99/7+3kvjHqFY357Osv3Xg6A7X/Wj+MGDQRgytSpnPHn83h7/HtI8NczT2XD9dbhvAsv48lnXuBHa6zKkLNPB2D4vQ/y7bdTOWT/vYp3gBlS5rnaybqg6mYx49/7wOzvoKKKmt/cQcWbjzH70Uvh/vMAqN7qUDr84iRm3XLaXJtW9FyDqs33Z8a/doH6WjoeOYy6N0YQX7wHQO0TV1D72OVzbdNhmyOZefUgKrotT/UWBzP7zrPpsMOJzH74ouIcr7XaKiutwJ03XAVAfX09W+20F9v/rN98622y4XpcfsHf5pv/l/Muot/mm3LhkLOZXVvLzJkzmTp1Gq+MeZ27b/oPvzv9z7z1zrus2Gd57rj7Aa686LyCH1NWlXvPutxv2sm+2d8l/1ZWQUU1EDBr2g/LO3RK5s1Dy67GnIkvQ+1MmFNP/bvPU7Xejs3uKubUoeqO0KEG6mvR0iuiJXoy593n2+54rGCee/Fl+izfi97L9cxr/WnTpjPylTHstfsuAHSorqbr4oujigpqa+uICGbNmkVVVRVXXncDBw3Yk+pq98+aUqn8h1IoaLKW1EnSnyRdkU6vJumXhdxn2VEFNac8ROdzXqX+7SeZ8/4rAHTY+VQ6nTmSqo33YNZ98/d25nwyjsq+m0GnpaC6I1Vr/Rwt2ev75dX9fk3N7x9msf3+CTVLAFD7yMUstu8Qqrc+gtqnrqHDLqcyu5G2rTzd+9AIfvmLbRtdNvq1N9h1wKEcfvwpvPNu8u1q0ocf0W2pJfnD4L+x+/6HcfrZQ/huxgy6dO7EDttuxe77H87yvZZj8S5deH3sOLbbZstiHk7mVCj/oSWSdpT0lqTxkk5rZr0fS6qX1GJtShGFu1xF0k3AS8DBEbGOpBrguYjYoIn1BwGDAC74+RIbH7pu54LFVnQ1Xel46FXMvu0M5nzy1vezq7c7DlUtxuwH/jnfJlU/GUD1lgNh9nTmfPIOUTuT2cMHoy7LpPXqoMNOv0dL9GDWDb+ba9uKVX5C1Xo7UvvM9XTY+RSor2X28LOJaV8U+EALq8s5L5U6hIKYXVtLv1/syb23XMMyS3eba9m0adNRhejcqRNPPP08f/nHhTw0/L+8NnYc+w48hhuuupj1112Lc867kC6dO3PiMYfNtf3pZw/hgH1254033+bp50eyxmp9Oebwg4t5eIXXpedC93ff3qki72S4+v1zmtyfpErgbWB7YDIwEtgvIsY2st7DwEzg6oi4tbl9FroM0jcihgC1ABExg2bq+BExNCI2iYhNFqlEDTBjCvXjn6XyR9vMNbvupTuoXH/nRjepe+FGZvxzR2ZctCfx3TfM+TzpUcW0LyDmQAS1zw+jYoUN5tu2ww6/YfaD59PhFycx+/5/UDfqdqq3Omy+9aw8PPnMC6y95mrzJWqALl0607lTJwC23nIz6urq+errb+jZozs9e3Rn/XXXAmDH7bZm7Li359q2YXqlFfsw/N4HueDvZ/HOu+8x8YPJBT6i7JGU99CCTYHxETEhImYDNwK7NbLe8cBtwGf5xFfoZD077U0HgKS+wKwC77N8dO4GNV2T8eqOVK3ejzmfvouWWfn7VarW2YH49N1GN1eXpZN/l+xF1Xo7Uffy8GS6a48ftl93J+Z8/NZc21Vtug/1Y0fAjG9RhxqISJJ7h5o2PDhrS/c+OIJddmy8BPL5F1/S8A341dffZM6cOSy15BJ0X2Zpei7bnQkTPwCSmnffVVaaa9sLLr2aE44+lLq6OurnzAGgQmLmzJmFO5iMkvIfWtAbmJQzPTmdl7Mv9Qb2AC7LN75Cn204E3gA6CNpGLAFMLDA+ywbFV2XZbEDzoeKClAFdaPvpn7sI3T89VDUoy/EHOKrD7+/EkRdl2WxAecxc2jyFbXjr69AnZci6uuYdevpMONbADr0P4OK3msBQXw1mVk3n/rDTqs7UvXjvZl56X4AzH58KB1/PRTqa5l53bHFPHzL04wZM3n2hVGc/ccfSlk33HonAPvttRsPjniCG269k8rKSjouthj/OvfM73t3f/r9bzj5jHOora2lT+9enDv4h/LoI489xbprr8my3ZcBYMN116b/PgNZfbW+rLn6qkU8woxoxdsHcku2qaERMbRhcSObzFtiOR84NSLq8+ipJ40WsmYNIGlpYDOSA3g+IvIqmk47sXd53/tpJbGo1qxtIbVBzXrCrtV555xV7qptrma9OTA4In6RTv8BICLOzVnnPX5I6ssA3wGDImJ4U+0W+mqQLYCZEXEvsCTwR0krFnKfZmYLog1r1iOB1SStLKkDMAC4K3eFiFg5IlaKiJWAW4FjmkvUUPia9aXAd5LWB04B3geuK/A+zcxar6IVQzMiog44DngQeBO4OSLekHSUpKMWNLxC16zrIiIk7QZcGBFXSTqkwPs0M2u1fGvH+YiI+4D75pnX6MnEiBiYT5uFTtZT03rNgcBW6XWF1QXep5lZq5X7280LXQbZl+RSvcMi4hOSy1d8S52ZlR1VKO+hFAras04T9L9ypj/ANWszK0NtWQYphIIka0lTaezpRMmlKhERXQuxXzOzBVXmubowyToiFi9Eu2ZmhdIue9bzktQD6NgwnZZDzMzKR5kn60LfFLOrpHeA94AngInA/YXcp5nZgmjDZ4MURKGvBvkzya3mb0fEysC2wDMF3qeZWatVVCjvoSTxFbj92oj4EqiQVBERjwEbFHifZmatV+Zd60LXrL+R1AV4Ehgm6TOgrsD7NDNrtTIvWRemZy1phXR0N5KnSZ1E8qjUd4H+hdinmdnCaMMHORVEoXrWw4GNImK6pNsiYk/g2gLty8xsobXXS/dyj3qVAu3DzKzNlHmuLliyjibGzczKUqme+ZGvQiXr9SVNIelh16Tj4NvNzaxMlXsZpMUTjJKGSOoqqVrSCElfSDqwuW0iojIiukbE4hFRlY43TDtRm1nZKfMr9/K6GmSHiJgC/JLkLb2rk7z1xcxs0VHm2TqfMkjDywJ2Bm6IiK/K/euCmVlrlXteyydZ3y1pHDADOEZSd2BmYcMyMyuuUt1Gnq8WyyARcRqwObBJRNSS3OSyW6EDMzMrKrViKIF8TjB2Ao4leVM5QC9gk0IGZWZWbKqoyHsohXz2+h9gNvDTdHoycE7BIjIzK4UyP8GYT7LuGxFDgFqAiJhByb4ImJkVSJkn63xOMM6WVEN6J6KkviRvLDczW2RIpSlv5CufZH0myRPz+kgaBmwBDCxkUGZmRVeiWnS+WkzWEfGwpJdJ3vgi4DcR8UXBIzMzK6LMX2ctaat0dGr671qSiIgnCxeWmVmRLQJlkNxbyzsCmwIvAT8vSERmZiWQ+afuRcRcb3aR1AcYUrCIzMxKIetlkEZMBtZp60DMzEpJFZWlDqFZ+dSsL+KHFwhUkLydfEwBYzIzK75FoGc9Kme8juTJe88UKB4zs9LIerKOCL/o1swWeZm9KUbSazT+/sSGV3OtV7CozMyKLcM9618WLQozsxLL7KV7EfF+MQMxMyupMr8aJJ/nWW8maaSkaZJmS6rPeVu5mdkiQVLeQynkczXIxcAA4BaSlw4cDKxayKDMzIouwzXr70XEeEmVEVEP/EfSswWOy8ysuMr8apB8ovtOUgdgtKQhkk4COhc4LjOzomrLMoikHSW9JWm8pNMaWb6bpFcljZY0StKWLbXZZLKW1PCexYPS9Y4DpgN9gD1bjNbMLEsqlP/QDEmVwL+BnYC1gP0krTXPaiOA9SNiA+BQ4MqWwmuuDHKFpC7ADcCNETEWOKulBs3MsqgNnw2yKTA+IiYASLoR2A0Y27BCREzLWb8zjd/TMpcme9YRsSHJtdb1wK1pd/1USSsuWPxmZmWs7d7B2BuYlDM9OZ03z+60h6RxwL0kvetmNVuzjoi3IuKsiFgLOARYEnhUkp8NYmaLlNbUrCUNSmvNDcOg3KYaaX6+nnNE3BERawK7A39uKb68rgZRctN8D2BZki775/lsZ2aWGa24GiQihgJDm1g8meTcXoPlgY+aaetJSX0lLdPcKxObjU5SP0mXpDs/BXgaWCMidm9uOzOzzGm7MshIYDVJK6dX0g0A7pp7V1pV6WUlkjYCOgBfNtdocw9ymgR8ANwInBURn7YUYVvq8lc/MtvmN3ij5UodgpWhweNqF7oNVbbNCcaIqJN0HPAgUAlcHRFvSDoqXX4ZyRV1B0uqBWYA+0ZEsycZmyuDbOnng5hZu9GGdzBGxH3AffPMuyxn/O/A31vTph/kZGYGZX8H44K8g9HMbNGzKDwbxMxskZfVnvU8L8qdT0ScUJCIzMxKIcM961HNLDMzW7SU+csHmjvB6Bflmln7kdUySANJ3YFTSZ4e1bFhfkT8vIBxmZkVV5mXQfL5UzIMeBNYmeSpexNJ7tAxM1t0tN0djAWRT7JeOiKuAmoj4omIOBTYrMBxmZkVlyryH0ogn0v3Gu7j/FjSLiQPJFm+cCGZmZVAmZdB8knW50haAvgdcBHQFTipoFGZmRVbVq8GaRAR96Sj3wI/K2w4ZmYlsghcDfIfGn9wdotvNjAzy4xFoAxyT854R2APmnmQtplZJmW9Zx0Rt+VOS7oBeKRgEZmZlcIi0LOe12rACm0diJlZSWX9BKOkqcxds/6E5I5GM7NFxyJQBlm8GIGYmZVUmZdBWvxTImlEPvPMzDItq3cwSuoIdAKWkbQU0PBnpyvQqwixmZkVT5n3rJsrgxwJnEiSmF/ih2Q9Bfh3YcMyMyuyrNasI+IC4AJJx0fERUWMycys+Mr8apB8/pTMkbRkw4SkpSQdU7iQzMxKoEL5D6UIL491joiIbxomIuJr4IiCRWRmVgpl/jzrfG6KqZCkiAgASZVAh8KGZWZWZFmtWed4ELhZ0mUkN8ccBTxQ0KjMzIotw1eDNDgVGAQcTXJFyEPAFYUMysys6LLes46IOcBl6YCkLUleQnBsYUMzMyuiigV5VFLx5BWdpA2A/YB9gfeA2wsYk5lZ8WW1DCJpdWAASZL+ErgJUET4bTFmtujJcBlkHPAU0D8ixgNI8rsXzWzRVObJurno9iR5HOpjkq6QtC0/3HJuZrZoKfPrrJtM1hFxR0TsC6wJPE7yRvNlJV0qaYcixWdmVhwVVfkPpQivpRUiYnpEDIuIXwLLA6OB0wodmJlZUZX5I1JbtdeI+CoiLo+InxcqIDOzkijzMkh5X1hoZlYsZX6C0cnazAycrM3MMqHCydrMrPwtAi8fMDNb9LXh1SCSdpT0lqTxkua7ek7SAZJeTYdnJa3fUpvuWZuZQZtd5ZE+8//fwPbAZGCkpLsiYmzOau8BW0fE15J2AoYCP2muXSdrMzNoyxOMmwLjI2ICgKQbgd2A75N1RDybs/7zJPewNMvJ2swM2jJZ9wYm5UxPpvle82HA/S016mRtZgatOsEoaRDJS1kaDI2IoQ2LG9kkmmjnZyTJesuW9ulkbWYGrepZp4l5aBOLJwN9cqaXBz6ab3fSesCVwE4R8WVL+/TVIGZm0JZXg4wEVpO0sqQOJO8FuGuuXUkrkLzE5aCIeDuf8NyzNjODNrsaJCLqJB1H8rLxSuDqiHhD0lHp8suA/wGWBi5Rst+6iNikuXadrM3MoE1vN4+I+4D75pl3Wc744cDhrWnTZZAimjJ1KiecfDo77rEfO/1qf14Z8/p867ww6mV22/cQdtnzAA487Id3El/735v55V4HssueB3DNsJu+n3/eBZfQf5+D+f0Zf/5+3vB7HuDa/95c2IOxhXLiiHc4+q5XOOqOUQy69XkA1vrFnhxz92jOHDuLXuts3OS2mx3yG465ezTH3PUKe/7zeqo6LAZAzRJLcdBV93P8A2M56Kr76dh1SQD6bPhTjr7zZY645Tm6rdAXgI6LL8GBV95b2IPMmkXpEam2cP4y5Hz6/fQnPHDHDdx507X0XWXFuZZPmTqVs/76Ty49/+/ce9swLjjvHADeHj+BW26/i1uuv5I7b7qWx598lonvT2Lq1Gm8MuY17r75Ourn1PPWO+8yc+Ys7rj7Pvbf+1elOERrhWsP3o7L9tiEoXttBsBn77zBTSfsw/ujnmpym8V79OInBx3L0L0245JdN6SiopJ1dtkXgC2P+D3vPf8oF+24Fu89/yhbHvF7AH766xO56YR9GPG/Z7DJfkcCsNUxp/PU5X8r8BFmTGVl/kMJFCxZK3GgpP9Jp1eQtGmh9lfupk2bzsiXx7DXHv0B6FBdTdfFF59rnbvvf5jtt92aXsv1BGDpbksB8O57E1l/3bWpqelIVVUVP954Ax5+7ElUIWpr64gIZs2aRVVVFVdeO4yDBuxNdbUrXFnzxYRxfPley+eaKiqrqO5YQ0VlJdU1nZj6WXKhwRrb9mf08OsBGD38etbcblcA6utqqV6shuqOnZhTW8tSfVaha49evD+y6T8K7VI77llfAmxO8nZ0gKkkt2C2S5M+/JBuSy3JH878C7sPGMjpZ53LdzNmzLXOxPc/YMqUqRx0+HH8av9DGX53cp386n1XYdTLY/j6m2+ZMWMmTz79HJ988ildOndmh223YfcBA1m+Vy8W79KZ18eOY7uf9SvFIVorRAQHXXU/g257gY33yb90OfWzj3j26v/lpEcn8LunJjFz6hTefeYRALosvSzTPv8EgGmff0Lnbj0AeHroEPqffSmbHXICLw67hG1PPJtHLxzc1oeUfWWerAvZ/fpJRGwk6RWA9B74DgXcX1mrq6tn7Li3+dOpJ7H+umtzzpDzGXr19Zx47A/X1dfX1/PGm+O45vILmTlzFgMOOZL111ubvqusxOEDD+DQo0+kU00Na6y+KpVVyVexIwYewBEDDwDg9LPO5YSjD+eW2+/i6edHssZqfTnmiIGlOFxrwdX7b83Uzz6mc7fuHHT1A3wxYRzvj3q6xe06dl2SNbftz/nbrcbMqd+wz/k3sl7//Xn17v82uc0n48Zw5YDknosVN9mSqZ9/jCT2+tcw5tTV8eDfT2H6l5+12bFlVpk/z7qQ0dWmDzQJAEndgTnNbSBpkKRRkkYNvfq6AoZWfD2X7UHPHt1Zf921Adhxu20YO27ur7w9e/Sg3083o1NNDd2WWpJNNtqAcW+PB2DvPfpzxw3/YdjVl7DkEl1ZcYU+c23b0NZKK/Zh+D0PcMGQP/PO+AlMfH8SVn6mfvYxANO/+pxxjwyn93o/zmu7VTbflq8nT+S7r79gTl0dbz48nD4bbg7AtC8/pUv3pITWpXtPpn81fwLe6ug/8sQlf2HrY//E4xedzat3DeMnBx3XRkeVcWX+Wq9CJusLgTuAHpL+AjwN/LW5DSJiaERsEhGbDDr04AKGVnzdl1manj17MGHi+wA89+JL9F1lpbnW2Xabfox6ZQx1dXXMmDGTV19/g74rJ+t8+dXXAHz08Sc89OgT/HLH7eba9oJLruCEow+nrq6O+jnJ38SKigpmzpxZ2AOzVquu6USHzl2+H++7xfZ89vYbeW377ceTWH79TanuWAPAypv/nM8njAPgrUfvYYPdDwJgg90P4q0Rd8+17QZ7HMzbj9/PzCnfUN2xhog5RMyhumOntjq0jFMrhuIrWBkkIoZJegnYluTodo+INwu1vyz406kncfIfz6K2ro4+vXtx7ll/5IZb7gBgv733oO8qK9Hvpz9h130OoaJC7LVHf1ZfdRUAjj/5j3zzzRSqqqo487TfsUTXrt+3+8hjT7Lu2j9i2R7dAdhwvXXov/dBrL5aX9ZcY7XiH6g1q8vSy7LvxbcCUFFZyWv33Mj4px9ize12Y+czzqdTt+7sf9mdfDJuDP93+C4s3mM5dv3z5Qw7clc+fPVFxj50O0fe/iJz6ur4+M0xvHTTFQA8fcUQ9v7fG9hwz1/z7ceTuOXEAd/vs7pjDevvfhDXH7YTAM9dcz77XHgz9bWzue13Bxb/QyhHZf7yAUU0+nyRhW84uZ1yPhHxQV4NfPdFYQKzTBu80XKlDsHK0OBxtQvd3Z3z+s1555yKdfYpeve6kCcY7yWpVwvoCKwMvAWsXcB9mpktmBLVovNVyDLIurnTkjYCjizU/szMFkp7TdbzioiXJeV3ytvMrOjK+9K9giVrSb/NmawANgI+L9T+zMwWSkU7TdZA7r3UdSQ17NsKuD8zs4XQDpN1ejNMl4g4pRDtm5m1ufZWs5ZUlT58e6O2btvMrGDK/HbzQvSsXySpT4+WdBdwCzC9YWFE3F6AfZqZLaR21rPO0Q34Evg5P1xvHSTvHTMzKy/trQxC8iyQ3wKv80OSbuC7Es2sLKnMbzcvRLKuBLrQ+HcKJ2szK1Ptr2b9cUScXYB2zcwKpx2WQcr7iM3MGtMOk/W2BWjTzKzA2lkZJCK+aus2zcwKrh32rM3Mskft72oQM7Pscc/azCwD2uHt5mZmGeSetZlZ+XMZxMwsA9rh7eZmZhnknrWZWfnzCUYzsyxwz9rMrPz5BKOZWRY4WZuZlT/3rM3MMsDJ2swsC5yszczKn3vWZmZZUN7JuryvAjczKxYp/6HFprSjpLckjZd0WiPL15T0nKRZkk7OJzz3rM3MoM3uYJRUCfwb2B6YDIyUdFdEjM1Z7SvgBGD3fNt1z9rMDEjKIPkOzdoUGB8REyJiNnAjsFvuChHxWUSMBGrzjc7J2swMWlUGkTRI0qicYVBOS72BSTnTk9N5C8VlEDMzoDUnGCNiKDC0FQ3FgkSUyz1rM7O2NRnokzO9PPDRwjbqnrWZGaC2e0TqSGA1SSsDHwIDgP0XtlEnazMzaLObYiKiTtJxwINAJXB1RLwh6ah0+WWSegKjgK7AHEknAmtFxJSm2nWyNjMD2vKmmIi4D7hvnnmX5Yx/QlIeyZuTtZkZ+HZzM7NscLI2Myt/7lmbmWWAX5hrZpYF7lmbmZW/8s7VTtZmZonyztZO1mZm4BOMZmbZ4GRtZlb+yvxqEEUs9JP7rMAkDUofyWj2Pf9etC/l/afEGgxqeRVrh/x70Y44WZuZZYCTtZlZBjhZZ4PrktYY/160Iz7BaGaWAe5Zm5llgJO1mVkG+KaYEpFUD7yWM2v3iJjYxLrTIqJLUQKzkpK0NDAinewJ1AOfp9ObRsTskgRmJeeadYm0JgE7WbdPkgYD0yLiHznzqiKirnRRWam4DFImJHWRNELSy5Jek7RbI+ssJ+lJSaMlvS6pXzp/B0nPpdveIsmJfREi6RpJ/5L0GPB3SYMlnZyz/HVJK6XjB0p6Mf0duVxSZanitrblZF06Nel/qNGS7gBmAntExEbAz4B/SvM9Bmx/4MGI2ABYHxgtaRngDGC7dNtRwG+LdhRWLKuT/Ix/19QKkn4E7Atskf6O1AMHFCc8KzTXrEtnRvofCgBJ1cBfJW0FzAF6A8sCn+RsMxK4Ol13eESMlrQ1sBbwTJrbOwDPFecQrIhuiYj6FtbZFtgYGJn+LtQAnxU6MCsOJ+vycQDQHdg4ImolTQQ65q4QEU+myXwX4HpJ5wFfAw9HxH7FDtiKanrOeB1zfytu+D0RcG1E/KFoUVnRuAxSPpYAPksT9c+AFeddQdKK6TpXAFcBGwHPA1tIWjVdp5Ok1YsYtxXfRJKfPZI2AlZO548A9pLUI13WLf2dsUWAe9blYxhwt6RRwGhgXCPrbAOcIqkWmAYcHBGfSxoI3CBpsXS9M4C3Cx6xlcptwMGSRpOUxt4GiIixks4AHpJUAdQCxwLvlypQazu+dM/MLANcBjEzywAnazOzDHCyNjPLACdrM7MMcLI2M8sAJ2szswxwsjYzywAnazOzDHCyNjPLACdrM7MMcLI2M8sAJ2szswxwsjYzywAnazOzDHCyNjPLACdrM7MMcLJuZyTVp29Uf13SLZI6LURb10jaKx2/UtJazay7jaSftrL9DSTtnDM9WNLJCxjrbpKG50z/QdL4nOn+ku6S1EvSrQuyD7NCcrJuf2ZExAYRsQ4wGzgqd6GkygVpNCIOj4ixzayyDdCqZA1sAOzc0kp5ehbYPGd6c2BKw/sKSWJ7JiI+ioi92mifjZLk1+lZqzlZt29PAaumvd7HJP0XeE1SpaTzJI2U9KqkIwGUuFjSWEn3Ag2JDkmPS9okHd9R0suSxkgaIWklkj8KJ6W9+n6Suku6Ld3HSElb5AYmqQNwNrBvus2+6aK10n1NkHRCzvoHSnoxXffyef/oRMTnwLcNLxYGepO8y7DhD8hPgWclrSTp9bTNgZJul/SApHckDcnZ3zRJf0mP8XlJy6bzGz2u9FvBUEkPAdct2I/L2rWI8NCOBmBa+m8VcCdwNEmvdzqwcrpsEHBGOr4YMIrkDdq/Ah4GKoFewDfAXul6jwObAN2BSTltdUv/HQycnBPHf4Et0/EVgDcbiXUgcHHO9GCSHvJiwDLAl0A18CPgbqA6Xe8SkpcJz9veNcDBwBrAjcC2wJD0s/ga6AisBLyes/8JJG+e70jy4tk+6bIA+qfjQ3I+r0aPK439JaCm1L8DHrI5+OtY+1OTvhUbkp71VSS9yhcj4r10/g7Aeg31aJJktRqwFXBDRNQDH0l6tJH2NwOebGgrIr5qIo7tSHrJDdNdJS0eEVNbiP/eiJgFzJL0GbAsSdLdGBiZtlcDfNbIts+kx1oJPAe8CPwPsCHwVkTMzImnwYiI+BZA0lhgRZI/RrOBe9J1XgK2b+640vG7ImJGC8dn1ign6/ZnRkRskDsjTSzTc2cBx0fEg/OstzNJj7I5ymMdSEpwmy9A8pqVM15P8jss4NqI+EML2z4LHE+SrK+IiKmSOpJ8s3imFfsDqI2IaGR+o8fVyGds1iquWVtjHgSOllQNIGl1SZ2BJ4EBaU17OeBnjWz7HLC1pJXTbbul86cCi+es9xBwXMOEpA0aaWvebZoyAtir4WShpG6SVmxkvbEk5Zt+wCvpvNEk9fRn89hPPvI5LrNWc7K2xlxJktheTk+2XU7Sc7wDeAd4DbgUeGLeDSM5kTcIuF3SGOCmdNHdwB4NJxiBE4BN0hOYY5nnqpTUYyQlhdwTjPOJ5CqUM4CHJL1KUldfrpH1AngB+CIiatPZzwGr0HbJOp/jMms1/fBNzszMypV71mZmGeBkbWaWAU7WZmYZ4GRtZpYBTtZmZhngZG1mlgFO1mZmGeBkbWaWAf8PFtJOekO9dxQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(cm2/np.sum(cm2), annot=True, \n",
    "            fmt='.2%', cmap='Oranges')\n",
    "\n",
    "ax.set_title('Nba game confusion matrix\\n\\n');\n",
    "ax.set_xlabel('\\nPredicte the Winner')\n",
    "ax.set_ylabel('Actual Values');\n",
    "\n",
    "## Ticket labels - List must be in alphabetical order\n",
    "ax.xaxis.set_ticklabels(['False','True'])\n",
    "ax.yaxis.set_ticklabels(['False','True'])\n",
    "\n",
    "## Display the visualization of the Confusion Matrix.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1738fc",
   "metadata": {},
   "source": [
    "### Display Optimized Confusion report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5485428e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      2558\n",
      "           1       0.87      0.89      0.88      3604\n",
      "\n",
      "    accuracy                           0.86      6162\n",
      "   macro avg       0.85      0.85      0.85      6162\n",
      "weighted avg       0.86      0.86      0.86      6162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = metrics.classification_report(Y_test,OY_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4739e5bc",
   "metadata": {},
   "source": [
    "---\n",
    "### Display Optimized accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1e673ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is up to :  85.75 %\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(Y_test,OY_pred)\n",
    "print(\"The accuracy score is up to : \",round(acc * 100 ,2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e68cf",
   "metadata": {},
   "source": [
    "---\n",
    "### Apply Standard scaler on training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa1f455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "Z = std.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035679d8",
   "metadata": {},
   "source": [
    "---\n",
    "### Standardized & Optimized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60fb6d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.27 s, sys: 5.84 ms, total: 1.28 s\n",
      "Wall time: 360 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, max_iter=7000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "regStd = LogisticRegression(max_iter = 7000, C = 10, penalty = 'l2', solver = 'lbfgs')\n",
    "regStd.fit(Z,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d601ac88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced accuracy score: 85.311  %\n",
      "CPU times: user 26.6 ms, sys: 0 ns, total: 26.6 ms\n",
      "Wall time: 19.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "SX_test = std.fit_transform(X_test)\n",
    "\n",
    "RSY_pred = regStd.predict(SX_test)\n",
    "\n",
    "print('balanced accuracy score:', round(metrics.balanced_accuracy_score(Y_test, RSY_pred) * 100, 4), ' %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e2335e",
   "metadata": {},
   "source": [
    "---\n",
    "# -------------------- Test -------------------- \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac0b9a",
   "metadata": {},
   "source": [
    "---\n",
    "### Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f9c507c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      coef\n",
      "G_home            0.020678\n",
      "G_away           -0.009924\n",
      "W_PCT_home        0.291163\n",
      "W_PCT_prev_home   0.040204\n",
      "FG_PCT_home       1.659707\n",
      "...                    ...\n",
      "FG_PCT_away_15g   0.141876\n",
      "FT_PCT_away_15g  -0.084391\n",
      "FG3_PCT_away_15g  0.070527\n",
      "AST_away_15g      0.065854\n",
      "REB_away_15g      0.094297\n",
      "\n",
      "[88 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(loss='log', penalty=\"l2\")\n",
    "sgd.fit(Z,Y_train)\n",
    "\n",
    "#coef.\n",
    "print(pd.DataFrame(sgd.coef_[0],index=X_train.columns,columns=[\"coef\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5574e7",
   "metadata": {},
   "source": [
    "---\n",
    "### Divide the coefficients by the standard deviations to de-standardize\n",
    "#### Little bit different than the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "882f68c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       coef\n",
      "G_home            -0.000069\n",
      "G_away            -0.002972\n",
      "W_PCT_home         1.842762\n",
      "W_PCT_prev_home    1.415552\n",
      "FG_PCT_home       27.873165\n",
      "...                     ...\n",
      "FG_PCT_away_15g    3.970639\n",
      "FT_PCT_away_15g   -1.615869\n",
      "FG3_PCT_away_15g   2.234937\n",
      "AST_away_15g       0.070231\n",
      "REB_away_15g       0.053847\n",
      "\n",
      "[88 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "#diviser les coefs. par les écarts-type pour dé-standardiser\n",
    "#un peu différents de \"reg\"\n",
    "#parce qu'algo différent de LogisticRegression ('lbfgs' par défaut)\n",
    "res = sgd.coef_[0] / std.scale_\n",
    "print(pd.DataFrame(res,index=X_train.columns,columns=[\"coef\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f48cb386",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'sort_values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-bf6992089044>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeta_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'sort_values'"
     ]
    }
   ],
   "source": [
    "beta_sorted = beta.sort_values(by='beta',ascending=False)\n",
    "print(beta_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "94723229",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beta_sorted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-208d08119144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'beta'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skyblue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'beta_sorted' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.barplot(x='beta',y=beta_sorted.index,data=beta_sorted,color='skyblue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59c0b8d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'beta_sorted' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-6bbc4d48f2dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeta_sorted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'beta_sorted' is not defined"
     ]
    }
   ],
   "source": [
    "beta_sorted.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b92d7d",
   "metadata": {},
   "source": [
    "---\n",
    "## SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9b0a1b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score : 85.21 %\n",
      "CPU times: user 9min 28s, sys: 126 ms, total: 9min 28s\n",
      "Wall time: 9min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf = svm.SVC(kernel='linear',C=10.0, gamma=1.0)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "SVY_pred = clf.predict(X_test)\n",
    "print(f\"Balanced accuracy score : {round(metrics.balanced_accuracy_score(Y_test, SVY_pred) * 100, 2)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "edecb10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score : 85.21 %\n",
      "CPU times: user 1.9 s, sys: 998 µs, total: 1.9 s\n",
      "Wall time: 1.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "SVY_pred = clf.predict(X_test)\n",
    "print(f\"Balanced accuracy score : {round(metrics.balanced_accuracy_score(Y_test, SVY_pred) * 100, 2)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63ebbc",
   "metadata": {},
   "source": [
    "---\n",
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87dc7319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.2 s, sys: 4.94 ms, total: 40.2 s\n",
      "Wall time: 40.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_leaf=4,\n",
       "                       min_samples_split=10, n_estimators=700, n_jobs=1,\n",
       "                       random_state=44)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestClassifier(random_state=44, n_jobs=1, bootstrap=True, \n",
    "                            criterion='entropy', n_estimators=700, max_depth=10, \n",
    "                            max_features='auto', min_samples_leaf=4, min_samples_split=10)\n",
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39b25692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score : (82.92961777331938, 2) %\n",
      "CPU times: user 748 ms, sys: 998 µs, total: 749 ms\n",
      "Wall time: 758 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "RFY_pred = rf.predict(X_test)\n",
    "\n",
    "print(f\"Balanced accuracy score : {metrics.balanced_accuracy_score(Y_test, RFY_pred) * 100, 2} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de19391",
   "metadata": {},
   "source": [
    "---\n",
    "### GridSearch on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21580d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'max_depth': 10, 'max_features': 'auto', 'min_samples_leaf': 4, 'min_samples_split': 10}\n",
      "accuracy : 84.24\n",
      "CPU times: user 7h 5min 41s, sys: 5.72 s, total: 7h 5min 47s\n",
      "Wall time: 7h 7min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_grid = { \n",
    "    'max_depth': [4,6,8,10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'min_samples_leaf': [2,4,6,8,10],\n",
    "    'min_samples_split': [2,4,6,8,10]\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rf,param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "CV_rfc.fit(X_train, Y_train)\n",
    "print(\"tuned hyperparameters :(best parameters) \",CV_rfc.best_params_)\n",
    "print(\"accuracy :\",round(CV_rfc.best_score_*100 ,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b990033",
   "metadata": {},
   "source": [
    "---\n",
    "### RandomizedSearch on Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c38ba681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hyperparameters :(best parameters)  {'max_samples': 7}\n",
      "accuracy : 58.29\n",
      "CPU times: user 7.5 s, sys: 12.8 ms, total: 7.52 s\n",
      "Wall time: 7.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_random= {\n",
    "#     'max_depth': [4,6,8,10],\n",
    "#     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#     'min_samples_leaf': [2,4,6,8,10],\n",
    "#     'min_samples_split': [2,4,6,8,10],\n",
    "    'max_samples' : list(range(1,10)),\n",
    "}\n",
    "\n",
    "CV_rfc = RandomizedSearchCV(rf, param_random, n_iter=1, random_state=44, n_jobs=1, cv=5)\n",
    "CV_rfc.fit(X_train, Y_train)\n",
    "print(\"tuned hyperparameters :(best parameters) \",CV_rfc.best_params_)\n",
    "print(\"accuracy :\",round(CV_rfc.best_score_*100 ,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6d952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
